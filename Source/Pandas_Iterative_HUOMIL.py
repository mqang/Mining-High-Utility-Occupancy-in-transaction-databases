# -*- coding: utf-8 -*-
"""DACNTT_W4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RQyKhmuInBy_IYiQuTyRPdvqTWOiE133
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("vijayuv/onlineretail")

print("Path to dataset files:", path)
path_onlineretail = path + "/OnlineRetail.csv"

import kagglehub

# Download latest version
path = kagglehub.dataset_download("heeraldedhia/groceries-dataset")

print("Path to dataset files:", path)
path_groceries = path + "/Groceries_dataset.csv"

path_mushroom = "/content/mushroom_utility_SPMF.txt"

path_chess = "/content/chess_utility_spmf.txt"

import pandas as pd
import time
import gc
import random
import psutil
from collections import defaultdict
from itertools import combinations

class GUOEntry:
    def __init__(self, tid, uo, ruo, util):
        self.tid = tid
        self.uo = uo
        self.ruo = ruo
        self.util = util

class GUOIL:
    def __init__(self):
        self.entries = []
        self.total_uo = 0
        self.total_util = 0

    def add(self, entry):
        self.entries.append(entry)
        self.total_uo += entry.uo
        self.total_util += entry.util

def load_online_retail(path, sample_size=None):
    try:
        df = pd.read_csv(path, encoding='ISO-8859-1', usecols=['InvoiceNo', 'StockCode', 'Quantity', 'UnitPrice', 'CustomerID'])
        df.dropna(subset=['CustomerID'], inplace=True)
        df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]
        profit_table = df.groupby('StockCode')['UnitPrice'].mean().to_dict()
        df = df.groupby(['InvoiceNo', 'StockCode'])['Quantity'].sum().reset_index()
        grouped = df.groupby('InvoiceNo')
        transactions = []
        for i, (tid, group) in enumerate(grouped):
            if sample_size and i >= sample_size:
                break
            transactions.append((tid, list(zip(group['StockCode'], group['Quantity']))))
        del df, grouped
        gc.collect()
        return transactions, profit_table
    except FileNotFoundError:
        raise FileNotFoundError(f"Error: {path} not found.")
    except Exception as e:
        raise Exception(f"Error loading OnlineRetail: {e}")

def load_kosarak(path, sample_size=None, default_profit=1.0):
    try:
        transactions = []
        profit_table = {}
        with open(path, 'r') as f:
            for i, line in enumerate(f):
                if sample_size and i >= sample_size:
                    break
                items = line.strip().split()
                if not items:
                    continue
                tid = f"T{i+1}"
                transaction = [(item, 1) for item in items]
                transactions.append((tid, transaction))
                for item in items:
                    if item not in profit_table:
                        profit_table[item] = default_profit
        return transactions, profit_table
    except FileNotFoundError:
        raise FileNotFoundError(f"Error: {path} not found.")
    except Exception as e:
        raise Exception(f"Error loading Kosarak: {e}")

def load_grocery(path, sample_size=None, default_profit=1.0):
    try:
        transactions = []
        profit_table = {}
        df = pd.read_csv(path)
        if 'itemDescription' not in df.columns:
            raise ValueError("Grocery CSV must contain 'itemDescription' column")
        grouped = df.groupby(['Member_number', 'Date'])['itemDescription'].apply(list).reset_index()
        for i, row in grouped.iterrows():
            if sample_size and i >= sample_size:
                break
            items = row['itemDescription']
            if not items:
                continue
            tid = f"{row['Member_number']}_{row['Date']}"
            transaction = [(item.strip(), 1) for item in items]
            transactions.append((tid, transaction))
            for item in items:
                if item not in profit_table:
                    profit_table[item] = default_profit
        del df, grouped
        gc.collect()
        return transactions, profit_table
    except FileNotFoundError:
        raise FileNotFoundError(f"Error: {path} not found.")
    except Exception as e:
        raise Exception(f"Error loading Grocery: {e}")

def load_mushrooms(path, sample_size=None, default_profit=1.0):
    try:
        transactions = []
        profit_table = {}
        with open(path, 'r') as f:
            for i, line in enumerate(f):
                if sample_size and i >= sample_size:
                    break
                parts = line.strip().split(':')
                if len(parts) < 2:
                    continue  # Skip malformed lines
                items = parts[0].strip().split()
                if not items:
                    continue
                # Extract items_utility if available, else use default_profit
                item_utilities = parts[2].strip().split() if len(parts) > 2 else []
                tid = f"T{i+1}"
                transaction = [(item.strip(), 1) for item in items]
                transactions.append((tid, transaction))
                # Build profit_table
                for j, item in enumerate(items):
                    if item not in profit_table:
                        if j < len(item_utilities):
                            try:
                                profit = float(item_utilities[j])
                                profit_table[item] = max(profit, 0.01)
                            except ValueError:
                                profit_table[item] = default_profit
                        else:
                            profit_table[item] = default_profit * random.uniform(1.0, 10.0)
        gc.collect()
        return transactions, profit_table
    except FileNotFoundError:
        raise FileNotFoundError(f"Error: {path} not found.")
    except Exception as e:
        raise Exception(f"Error loading Mushrooms: {e}")

def load_chess(path, sample_size=None, default_profit=1.0):
    try:
        transactions = []
        profit_table = {}
        with open(path, 'r') as f:
            for i, line in enumerate(f):
                if sample_size and i >= sample_size:
                    break
                parts = line.strip().split(':')
                if len(parts) < 2:
                    continue  # Skip malformed lines
                items = parts[0].strip().split()
                if not items:
                    continue
                # Extract items_utility if available, else use default_profit
                item_utilities = parts[2].strip().split() if len(parts) > 2 else []
                tid = f"T{i+1}"
                # Filter numeric items to match Spark's rlike("^[0-9]+$")
                transaction = [(item.strip(), 1) for item in items if item.isdigit()]
                if not transaction:
                    continue  # Skip if no valid items
                transactions.append((tid, transaction))
                # Build profit_table
                for j, item in enumerate(items):
                    if item.isdigit() and item not in profit_table:
                        if j < len(item_utilities):
                            try:
                                profit = float(item_utilities[j])
                                profit_table[item] = max(profit, 0.01)
                            except ValueError:
                                profit_table[item] = default_profit
                        else:
                            profit_table[item] = default_profit * random.uniform(1.0, 10.0)
        gc.collect()
        return transactions, profit_table
    except FileNotFoundError:
        raise FileNotFoundError(f"Error: {path} not found.")
    except Exception as e:
        raise Exception(f"Error loading Chess: {e}")

def load_dataset(dataset_name, path, sample_size=None, default_profit=1.0):
    dataset_name = dataset_name.lower()
    if dataset_name == 'online_retail':
        return load_online_retail(path, sample_size)
    elif dataset_name == 'kosarak':
        return load_kosarak(path, sample_size, default_profit)
    elif dataset_name == 'grocery':
        return load_grocery(path, sample_size, default_profit)
    elif dataset_name == 'mushrooms':
        return load_mushrooms(path, sample_size, default_profit)
    elif dataset_name == 'chess':
        return load_chess(path, sample_size, default_profit)
    else:
        raise ValueError(f"Unknown dataset: {dataset_name}")

def transaction_utility(transaction, profit_table):
    return sum(qty * profit_table.get(item, 0) for item, qty in transaction)

def utility(item, transaction, profit_table):
    for i, qty in transaction:
        if i == item:
            return qty * profit_table.get(i, 0)
    return 0

def huomil(transactions, profit_table, minUtil, minUO):
    item_counts = defaultdict(int)
    cooccurrence = defaultdict(list)
    INVALID_ITEMS = {"M", "POST", "BANK CHARGES", "DOT", "ADJUST", "C2", "AMAZONFEE"}
    tx_dict = {}
    for tid, items in transactions:
        items = [(i, q) for i, q in items if i not in INVALID_ITEMS]
        if not items:
            continue
        tx_dict[tid] = items
        for i, _ in items:
            item_counts[i] += 1
        for (i1, _), (i2, _) in combinations(items, 2):
            if i1 < i2:
                cooccurrence[(i1, i2)].append(tid)
            elif i2 < i1:
                cooccurrence[(i2, i1)].append(tid)
    item_order = sorted(item_counts.keys())
    results = []
    guo = defaultdict(GUOIL)
    for tid, items in tx_dict.items():
        tu = transaction_utility(items, profit_table)
        if tu == 0:
            continue
        for i, _ in items:
            util = utility(i, items, profit_table)
            uo = util / tu
            guo[i].add(GUOEntry(tid, uo, 0, util))
    valid_items = []
    valid_items_set = set()
    for i in item_order:
        g = guo[i]
        if len(g.entries) > 0:
            avg_uo = g.total_uo / len(g.entries)
            if g.total_util >= minUtil and avg_uo >= minUO:
                results.append(([i], g.total_util, round(avg_uo, 4)))
                valid_items.append(i)
                valid_items_set.add(i)
    for (i1, i2), tids in cooccurrence.items():
        if i1 not in valid_items_set or i2 not in valid_items_set:
            continue
        total_util = 0
        total_uo = 0
        for tid in tids:
            items = tx_dict[tid]
            tu = transaction_utility(items, profit_table)
            u1 = utility(i1, items, profit_table)
            u2 = utility(i2, items, profit_table)
            if tu == 0:
                continue
            total_util += u1 + u2
            total_uo += (u1 + u2) / tu
        if len(tids) > 0:
            avg_uo = total_uo / len(tids)
            if total_util >= minUtil and avg_uo >= minUO:
                results.append(([i1, i2], total_util, round(avg_uo, 4)))
    return results, tx_dict, item_counts, cooccurrence, guo, valid_items, valid_items_set

def process_dataset(dataset_name, path, minUtil, minUO, sample_size=None, default_profit=1.0):
    process = psutil.Process()
    print(f"\n=== Processing {dataset_name.upper()} Dataset ===")
    start_time = time.time()
    mem_start = process.memory_info().rss / (1024 ** 2)
    # if mem_start < 0:
    #   mem_start = 0

    try:
        transactions, profit_table = load_dataset(dataset_name, path, sample_size, default_profit)
    except Exception as e:
        print(f"Failed to load {dataset_name}: {e}")
        return

    print(f"Number of transactions loaded: {len(transactions)}")

    results, tx_dict, item_counts, cooccurrence, guo, valid_items, valid_items_set = huomil(
        transactions, profit_table, minUtil=minUtil, minUO=minUO
    )

    one_itemsets = [r for r in results if len(r[0]) == 1]
    two_itemsets = [r for r in results if len(r[0]) == 2]

    one_itemsets.sort(key=lambda x: x[1], reverse=True)
    two_itemsets.sort(key=lambda x: x[1], reverse=True)

    results = one_itemsets + two_itemsets

    print(f"\n======HUOMIL 1-ITEM ({dataset_name})======")
    print(f"{'Pattern':<20} {'Total Util':<15} {'AvgUO':<10}")
    print("-" * 45)
    for pattern, total_util, avg_uo in one_itemsets[:20]:
        pattern_str = str(pattern[0])
        print(f"{pattern_str:<20} {total_util:<15.4f} {avg_uo:<10.4f}")
    print(f"Number of 1-itemsets: {len(one_itemsets)}")
    print("=========================\n")

    print(f"======HUOMIL 2-ITEM ({dataset_name}, Sorted by Total Util)======")
    print(f"{'Pattern':<30} {'Total Util':<15} {'AvgUO':<10}")
    print("-" * 55)
    for pattern, total_util, avg_uo in two_itemsets[:20]:
        pattern_str = ", ".join(pattern)
        print(f"{pattern_str:<30} {total_util:<15.4f} {avg_uo:<10.4f}")
    print(f"Number of 2-itemsets: {len(two_itemsets)}")
    print("=========================\n")

    end_time = time.time()
    mem_before_cleanup = process.memory_info().rss / (1024 ** 2)
    print(f"=== {dataset_name.upper()} Results ===")
    print(f"1-itemsets: {len(one_itemsets)}")
    print(f"2-itemsets: {len(two_itemsets)}")
    print(f"Total patterns: {len(results)}")
    print(f"Execution time: {end_time - start_time:.2f} seconds")
    print(f"Memory Usage Before Cleanup: {mem_before_cleanup - mem_start:.2f} MB")

    print("\n=== Cleaning Up Memory ===")
    results.clear()
    one_itemsets.clear()
    two_itemsets.clear()
    transactions.clear()
    profit_table.clear()
    tx_dict.clear()
    item_counts.clear()
    cooccurrence.clear()
    valid_items.clear()
    valid_items_set.clear()
    for g in guo.values():
        g.entries.clear()
    guo.clear()
    del results, one_itemsets, two_itemsets
    del transactions, profit_table
    del tx_dict, item_counts, cooccurrence, guo
    del valid_items, valid_items_set
    gc.collect()
    mem_after_cleanup = process.memory_info().rss / (1024 ** 2)
    print(f"Memory Usage After Cleanup: {mem_after_cleanup - mem_start:.2f} MB")
    print(f"Memory Freed: {(mem_before_cleanup - mem_after_cleanup):.2f} MB")
    print("=========================\n")

dataset_configs = [
    {
        'name': 'online_retail',
        'path': path_onlineretail,
        'sample_size': None,
        'minUtil': 500,
        'minUO':0.075
    },
    {
        'name': 'kosarak',
        'path': 'kosarak.dat',
        'sample_size': 100000,
        'default_profit': 1.0,
        'minUtil': 15,
        'minUO':0.15
    },
    {
        'name': 'grocery',
        'path': path_groceries,
        'sample_size': None,
        'default_profit': 1.0,
        'minUtil': 12,
        'minUO':0.25
    },
    {
        'name': 'mushrooms',
        'path': path_mushroom,
        'sample_size': None,
        'default_profit': 1.0,
        'minUtil': 400,
        'minUO':0.001
    },
    {
        'name': 'chess',
        'path': path_chess,
        'sample_size': None,
        'default_profit': 1.0,
        'minUtil': 750,
        'minUO':0.001
    }
]


for config in dataset_configs:
    process_dataset(
        dataset_name=config['name'],
        path=config['path'],
        minUtil=config['minUtil'],
        minUO=config['minUO'],
        sample_size=config.get('sample_size'),
        default_profit=config.get('default_profit', 1.0),
    )